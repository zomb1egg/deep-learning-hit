{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f19443-dcc5-483e-ad2c-800081f5db16",
   "metadata": {},
   "source": [
    "# Homework #3: Proof that ReLU follows Universal Approximation Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eab20a",
   "metadata": {},
   "source": [
    "### The Universal Approximation Theorem is defined as follows: \n",
    "$\\\\[5mm]$\n",
    "$\n",
    "\\text{Let } f : [a, b] \\to \\mathbb{R} \\text{ be a continuous function, where } [a, b] \\subset \\mathbb{R}. \\text{ For any } \\epsilon > 0, \\\\\n",
    "\\text{there exists a feedforward neural network with a single hidden layer such that} \\\\\n",
    "\\sup_{x \\in [a, b]} \\left| f(x) - \\hat{f}(x) \\right| < \\epsilon,\n",
    "\\text{ where } \\hat{f}(x) \\text{ is the output of the neural network.}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59eb3f",
   "metadata": {},
   "source": [
    "### steps to prove that UAT applies on ReLU\n",
    "1) ReLU is a continues function\n",
    "2) Apply Stoneâ€“Weierstrass theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010822cc",
   "metadata": {},
   "source": [
    "#### lets first begin by defining the ReLU function itself:\n",
    "\n",
    "$\n",
    "\\text{ReLU}(x) = \n",
    "\\begin{cases} \n",
    "x & \\text{if } x \\geq 0, \\\\\n",
    "0 & \\text{if } x < 0.\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "#### now, lets tackle each point one by one.\n",
    "first, lets prove that ReLU is a continues function: \\\n",
    "from our definition we know that for every $ x >= 0 $ our ReLU function is just $x$. $x$ being a continues function means that ReLU is continues when $x > 0$. \\\n",
    "when $x < 0$, ReLU is $0$, meaning it constant and therefor continues. \\\n",
    "now lets prove what happens in the point $x = 0$ from both sides: \\\n",
    "\\\n",
    "$\n",
    "\\displaystyle\n",
    "\\lim_{x \\to 0^+} ReLU(x) = \\lim_{x \\to 0^+} x = 0 \n",
    "$  \n",
    "<!--ah yes, here we go again with this github KaTeX rendering -->\n",
    "$\n",
    "\\displaystyle\n",
    "\\lim_{x \\to 0^-} ReLU(x) = \\lim_{x \\to 0^-} 0 = 0 \n",
    "$ \\\n",
    "\\\n",
    "our upper and lower limits are equal thus proving that ReLU is continues\n",
    "\\\n",
    "\\\n",
    "next, lets apply the Weierstrass Approximation Theorem:\\\n",
    "$\n",
    "\\text{Suppose } f \\text{ is a continuous real-valued function defined on the real interval } [a, b]. \\\\\n",
    "\\text{For every } \\epsilon > 0, \\text{ there exists a polynomial } p \\text{ such that for all } x \\in [a, b], \\\\\n",
    "\\sup_{x \\in [a, b]} |f(x) - p(x)| < \\epsilon.\n",
    "$ \\\n",
    "In other words, any continuous function on a closed and bounded interval can be uniformly approximated on that interval by polynomials to any degree of accuracy. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
